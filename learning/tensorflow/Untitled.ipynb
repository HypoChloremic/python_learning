{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GLOBAL] importing\n",
      "[GLOBAL] Setting os environ TF_CPP_MIN_LOG_LEVEL to '2' \n",
      "Shape of x: (100, 2)\n",
      "[GLOBAL] Starting\n",
      "(100, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100,) for Tensor 'Placeholder_3:0', which has shape '(?, 2, 1, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-29ab4369dfc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# of the graph in order to drive the entire thing, which\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# makes sense.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1094\u001b[0m             raise ValueError(\n\u001b[0;32m   1095\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0;32m   1098\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (100,) for Tensor 'Placeholder_3:0', which has shape '(?, 2, 1, 1)'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We are trying to produce a simple neural network that does\n",
    "linear regression. \n",
    "(cc) 2017 Ali Rassolie\n",
    "\"\"\"\n",
    "print(\"[GLOBAL] importing\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"[GLOBAL] Setting os environ TF_CPP_MIN_LOG_LEVEL to '2' \")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# the function\n",
    "def f(x):\n",
    "\treturn x\n",
    "\n",
    "x = [[np.random.randint(10), np.random.randint(10)] for i in range(60000)]\n",
    "y = []\n",
    "\n",
    "for i in x: \n",
    "\tif i[1] > f(i[0]):\n",
    "\t\ty.append(1)\n",
    "\telse: \n",
    "\t\ty.append(0) \n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Shape of x: {x[:100].shape}\")\n",
    "\n",
    "\"\"\"\n",
    "So if we look at the list that we provide the placeholder\n",
    "in the case of the example provided by Martin Gorer, we \n",
    "noted that he provided a so called tensor with the following\n",
    "dimensions [None, 28,28,1] where the None represented the amount\n",
    "of data input, and the 28x28x1 represented the dimensions of the \n",
    "image where the 1 represented the color channel which was only one. \n",
    "In our case, we are simply inputting y and x coordinates, pairwise. \n",
    "So we will need to use None as well, cuz we dont know how many inputs\n",
    "we are going to give at one time. the 2 in turn represents the \n",
    "dimensions of that input, which with consideration are just 2 values. \n",
    "\"\"\"\n",
    "print(\"[GLOBAL] Starting\")\n",
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "# similarly, we will only need two weights, and one node?\n",
    "W = tf.Variable(tf.zeros([2,1]))\n",
    "# One bias value for the one node. \n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# This model is in effect the operation we are going to perform\n",
    "# in our node of interest. Note that we are in effect constructing\n",
    "# a graph, which we then are going to drive with the Session.run \n",
    "# method later. The model will thus become a vector containing\n",
    "# the activations of the neuron. \n",
    "model  = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "# In this case we only have two labels, for each cluster. \n",
    "labels = tf.placeholder(tf.float32, [None, 2, 1, 1]) \n",
    "\n",
    "# The error function\n",
    "error = -tf.reduce_sum(labels*tf.log(model))\n",
    "# So here we select what kind of optimization method we want to use\n",
    "# and the learning rate in turn. tf.train contains the class. \n",
    "# I am unsure whether the 0.003 value represents the amount with\n",
    "# which we are going to change the weights and the biases. Also,\n",
    "# does it know automatically what weights it is going to change?\n",
    "optimizer  = tf.train.GradientDescentOptimizer(0.003)\n",
    "# Furthermore, the GradientDescentOptimizer has a minimze method\n",
    "# associated with it, which we would like to feed the error\n",
    "# function into, which in effect tells it the cost function it \n",
    "# should use. \n",
    "train_step = optimizer.minimize(error)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "# Now I assue we are running the init because we want \n",
    "# to tell Session how the graph looks like. \n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "\ttrain_data = {X: x[(i*100):((i+1)*100)], labels: y[(i*100):((i+1)*100)]}\n",
    "\tprint(train_data[X].shape)\n",
    "\t# Aight, so it seems that we are running the last operation\n",
    "\t# of the graph in order to drive the entire thing, which\n",
    "\t# makes sense. \n",
    "\tsess.run(train_step, feed_dict=train_data)\n",
    "\n",
    "\n",
    "print(\"[GLOBAL] Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
